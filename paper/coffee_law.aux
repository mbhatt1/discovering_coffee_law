\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{hypothetical2024drift}
\citation{liu2023lost}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{vaswani2017attention}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Contributions}{2}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Attention Mechanics}{2}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}The Query Drift Hypothesis}{2}{subsection.2.2}\protected@file@percent }
\newlabel{eq:brownian}{{3}{2}{The Query Drift Hypothesis}{equation.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Stochastic Process Basics}{3}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Experimental Design}{3}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Core Experiments}{3}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Experiment 1: Embedding Variance Growth}{3}{paragraph*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Experiment 2: Alignment Decay}{3}{paragraph*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Experiment 3: Loss Scaling}{3}{paragraph*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Experiment 4: Memory Retrieval}{3}{paragraph*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Experimental Conditions}{3}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Statistical Rigor and Controls}{4}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Sample Size Justification}{4}{paragraph*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Position Selection Rationale}{4}{paragraph*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Cross-Validation Procedure}{4}{paragraph*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Significance Testing}{4}{paragraph*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Potential Confounds}{4}{paragraph*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Empirical Observations}{4}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Observation 1: Variance Saturates}{5}{subsection.4.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Embedding variance at different token positions.}}{5}{table.caption.10}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:variance_raw}{{1}{5}{Embedding variance at different token positions}{table.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Variance growth across token positions from latest experimental run (3 trials). The rapid saturation from position 10 to 20, followed by flat behavior from 20 to 100, is visible across all trials. Hurst exponent H=0.096 confirms mean-reversion. Trial-to-trial consistency validates the measurement reliability.}}{5}{figure.caption.11}\protected@file@percent }
\newlabel{fig:variance_raw}{{1}{5}{Variance growth across token positions from latest experimental run (3 trials). The rapid saturation from position 10 to 20, followed by flat behavior from 20 to 100, is visible across all trials. Hurst exponent H=0.096 confirms mean-reversion. Trial-to-trial consistency validates the measurement reliability}{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Observation 2: Alignment Decays Slowly}{5}{subsection.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Alignment decay on log-log scale from latest experimental run (3 trials). Observed decay follows $t^{-0.24}$ rather than Brownian $t^{-0.5}$. All three trials show consistent exponents ($\beta = 0.239$) with $R^2 = 0.948$, demonstrating robust mean-reversion.}}{6}{figure.caption.12}\protected@file@percent }
\newlabel{fig:alignment}{{2}{6}{Alignment decay on log-log scale from latest experimental run (3 trials). Observed decay follows $t^{-0.24}$ rather than Brownian $t^{-0.5}$. All three trials show consistent exponents ($\beta = 0.239$) with $R^2 = 0.948$, demonstrating robust mean-reversion}{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Observation 3: Loss Does Not Scale}{6}{subsection.4.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Mean loss at different context lengths.}}{7}{table.caption.13}\protected@file@percent }
\newlabel{tab:loss}{{2}{7}{Mean loss at different context lengths}{table.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Loss scaling across context lengths. Both trials show similar flat/U-shaped profiles (solid lines with markers) that contradict the Brownian prediction of monotonic decrease (red dashed line). The minimum at 200 tokens followed by slight increase suggests quality saturation rather than unbounded degradation.}}{7}{figure.caption.14}\protected@file@percent }
\newlabel{fig:loss_scaling}{{3}{7}{Loss scaling across context lengths. Both trials show similar flat/U-shaped profiles (solid lines with markers) that contradict the Brownian prediction of monotonic decrease (red dashed line). The minimum at 200 tokens followed by slight increase suggests quality saturation rather than unbounded degradation}{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Observation 4: Perfect Memory Retention}{7}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Cross-Model Validation}{7}{subsection.4.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Variance across embedding models.}}{8}{table.caption.15}\protected@file@percent }
\newlabel{tab:embedding_models}{{3}{8}{Variance across embedding models}{table.caption.15}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Variance across completion models (using text-embedding-3-small).}}{8}{table.caption.16}\protected@file@percent }
\newlabel{tab:completion_models}{{4}{8}{Variance across completion models (using text-embedding-3-small)}{table.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Cross-model variance comparison. Left: Embedding models of different dimensionalities (1536d vs 3072d) show similar variance magnitudes. Right: Completion models of different scales (GPT-4o-mini vs GPT-4o) show 1.5× variance difference. Despite magnitude differences, all models exhibit saturation behavior, confirming architectural rather than model-specific dynamics.}}{8}{figure.caption.17}\protected@file@percent }
\newlabel{fig:cross_model}{{4}{8}{Cross-model variance comparison. Left: Embedding models of different dimensionalities (1536d vs 3072d) show similar variance magnitudes. Right: Completion models of different scales (GPT-4o-mini vs GPT-4o) show 1.5× variance difference. Despite magnitude differences, all models exhibit saturation behavior, confirming architectural rather than model-specific dynamics}{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Summary of Observations}{8}{subsection.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}Robustness Validation}{8}{subsection.4.7}\protected@file@percent }
\citation{liu2023lost}
\citation{vaswani2017attention}
\citation{clark2019does,vig2019analyzing}
\citation{liu2023lost}
\citation{press2021alibi}
\citation{bowman2015generating}
\citation{white2023prompt}
\bibstyle{plainnat}
\bibcite{vaswani2017attention}{{1}{2017}{{Vaswani et al.}}{{}}}
\bibcite{liu2023lost}{{2}{2023}{{Liu et al.}}{{}}}
\bibcite{clark2019does}{{3}{2019}{{Clark et al.}}{{}}}
\bibcite{vig2019analyzing}{{4}{2019}{{Vig}}{{}}}
\bibcite{press2021alibi}{{5}{2021}{{Press et al.}}{{}}}
\bibcite{bowman2015generating}{{6}{2015}{{Bowman et al.}}{{}}}
\bibcite{white2023prompt}{{7}{2023}{{White et al.}}{{}}}
\bibcite{hypothetical2024drift}{{8}{2024}{{Hypothetical}}{{}}}
\gdef \@abspage@last{8}
