\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[margin=0.75in]{geometry}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage[table]{xcolor}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows,positioning,fit,backgrounds,shadows,shadows.blur}
\usepackage{pgfplots}
\pgfplotsset{compat=1.17}
\usepackage{subcaption}
\usepackage{float}
\usepackage{multirow}
\usepackage{tcolorbox}
\usepackage{enumitem}
\usepackage{microtype}
\usepackage{titlesec}
\usepackage{tabularx}
\usepackage{array}
\usepackage{natbib}
\usepackage{url}

% Professional spacing
\setlength{\parskip}{0pt}
\setlength{\parindent}{10pt}
\setlength{\columnsep}{0.25in}

% Professional section formatting
\titleformat{\section}{\large\bfseries\sffamily}{\thesection}{0.5em}{}[\vspace{-0.5em}]
\titleformat{\subsection}{\normalsize\bfseries\sffamily}{\thesubsection}{0.5em}{}[\vspace{-0.3em}]
\titleformat{\subsubsection}{\small\bfseries\sffamily}{\thesubsubsection}{0.5em}{}

% Figma-inspired color palette
\definecolor{figmapurple}{RGB}{151,71,255}
\definecolor{figmablue}{RGB}{0,114,255}
\definecolor{figmateal}{RGB}{14,178,178}
\definecolor{figmagreen}{RGB}{0,200,117}
\definecolor{figmaorange}{RGB}{255,123,0}
\definecolor{figmared}{RGB}{255,59,92}
\definecolor{figmapink}{RGB}{255,99,205}
\definecolor{figmayellow}{RGB}{255,198,0}

% UI colors
\definecolor{figmabg}{RGB}{249,250,251}
\definecolor{figmatext}{RGB}{31,35,40}
\definecolor{figmagray}{RGB}{196,201,208}
\definecolor{figmalightgray}{RGB}{243,244,246}

% Legacy color names
\definecolor{accentblue}{RGB}{0,114,255}
\definecolor{darkgray}{RGB}{31,35,40}
\definecolor{darkblue}{RGB}{0,91,204}
\definecolor{lightgray}{RGB}{249,250,251}
\definecolor{alertred}{RGB}{255,59,92}
\definecolor{rowgray}{RGB}{249,250,251}
\definecolor{rowhighlight}{RGB}{232,240,254}
\definecolor{lightgreen}{RGB}{220,252,231}
\definecolor{lightyellow}{RGB}{255,251,230}

% Result boxes
\newtcolorbox{resultbox}[1][]{
  colback=lightgray,
  colframe=darkgray,
  boxrule=0.5pt,
  arc=2pt,
  left=8pt,
  right=8pt,
  top=6pt,
  bottom=6pt,
  fontupper=\small\sffamily,
  #1
}

% Hyperlinks
\usepackage[colorlinks=true,linkcolor=accentblue,citecolor=darkgray,urlcolor=accentblue]{hyperref}

% Custom commands
\newcommand{\E}{\mathbb{E}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\vq}{\mathbf{q}}
\newcommand{\vk}{\mathbf{k}}
\newcommand{\vv}{\mathbf{v}}
\newcommand{\vu}{\mathbf{u}}

% Theorem environments
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{definition}{Definition}
\newtheorem{corollary}{Corollary}
\newtheorem{observation}{Observation}

% Title and authors
\title{\vspace{-2em}\textbf{\Large The COFFEE Law: Saturating Embedding Variance in LLMs}\\[0.3em]
\large Empirical Evidence for Ornstein-Uhlenbeck Dynamics\vspace{-1em}}

\author{
Manish\thanks{Bhatt}}


\date{\vspace{-1em}}

\begin{document}

\maketitle

\begin{abstract}
\noindent We present empirical evidence that output embedding dynamics in transformer-based language models follow Ornstein-Uhlenbeck (OU) rather than Brownian motion. Using 6 token positions across 3 trials, we validate all three OU properties: (1) variance saturation at $\sigma^2_\infty \approx 0.109$ (OU $R^2 = 0.67$ vs Brownian $R^2 < 0$); (2) relaxation time $\tau \approx 10.6$ tokens; and (3) stationary distribution evidence via exponential autocorrelation decay and entropy saturation. We term this the ``COFFEE Law''---an empirical law of saturating embedding dynamics.

\textbf{Limitations}: (1) 6 measurement positions---denser sampling would strengthen parameter estimates; (2) single prompt family---cross-prompt confidence intervals needed for generalization claims; (3) we measure output embeddings, not internal attention states; (4) our retrieval experiment differs from ``Lost in the Middle'' protocols. Code and data available at \url{https://github.com/mbhatt1/coffee-law}.
\end{abstract}

\noindent\textbf{\small Keywords:} Embedding Dynamics, Variance Saturation, Ornstein-Uhlenbeck Process, Context Engineering, Large Language Models

\vspace{0.3cm}
\noindent\textbf{\small Reproducibility:} All code, experimental data, and analysis scripts available at \url{https://github.com/mbhatt1/coffee-law}

\section{Introduction}

Understanding how model representations evolve during generation is important for retrieval-augmented generation (RAG), multi-turn dialogue, and long-context applications. The \textit{Query Drift Hypothesis} \citep{hypothetical2024drift} models internal query evolution as Brownian motion, predicting unbounded variance growth and progressive information loss \citep{liu2023lost}.

We present empirical evidence that output embedding dynamics instead follow an Ornstein-Uhlenbeck (OU) process---a mean-reverting stochastic model where variance saturates rather than growing unboundedly. We validate all three OU properties: variance saturation, relaxation time, and stationary distribution behavior. We term this the \textbf{COFFEE Law}: \textbf{C}ontext-\textbf{O}ptimized \textbf{F}low with \textbf{F}ast \textbf{E}xponential \textbf{E}quilibrium.

\subsection{Contributions}

\begin{enumerate}
\item \textbf{Empirical law}: We document the COFFEE Law---embedding variance saturates at $\sigma^2_\infty \approx 0.109$ with relaxation time $\tau \approx 10.6$ tokens.
\item \textbf{OU validation}: We test all three OU properties: saturation (OU $R^2 = 0.67$ vs Brownian $R^2 < 0$), relaxation time, and stationary behavior (exponential autocorrelation decay, entropy saturation).
\item \textbf{Cross-condition consistency}: Saturation persists across temperatures (0.0--1.5), domains (scientific to conversational), and models (GPT-4o-mini, GPT-4o).
\end{enumerate}

\subsection{Limitations}

\begin{enumerate}
\item \textbf{Sparse sampling}: 6 measurement positions---denser sampling would strengthen parameter estimates.
\item \textbf{Single prompt family}: Cross-prompt confidence intervals needed for generalization claims.
\item \textbf{Proxy measurements}: We measure output embeddings, not internal attention states.
\item \textbf{Different retrieval protocol}: Our retrieval experiment differs from ``Lost in the Middle'' methodology.
\end{enumerate}

Code available at \texttt{github.com/mbhatt1/coffee-law}.

\section{Background}

\subsection{Attention Mechanics}

In transformer architectures \citep{vaswani2017attention}, attention computes weighted sums over value vectors:
\begin{equation}
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^\top}{\sqrt{d_k}}\right)V
\end{equation}
At generation step $t$, the query $\vq_t$ attends over all previous keys $\{\vk_1, \ldots, \vk_t\}$. Internal queries $\vq_t$ are inaccessible in closed models; we use output embeddings $\mathbf{e}_t$ as proxies (see Section~\ref{sec:metrics}).

\subsection{The Query Drift Hypothesis}

The Query Drift Hypothesis models query evolution as Brownian motion:
\begin{equation}
\vq_{t+1} = \vq_t + \epsilon_t, \quad \epsilon_t \sim \mathcal{N}(0, \sigma^2 I)
\label{eq:brownian}
\end{equation}
This predicts:
\begin{align}
\text{Variance growth:} & \quad \E[\|\vq_t - \vq_0\|^2] = \sigma^2 t \\
\text{Alignment decay:} & \quad C_t \propto t^{-1/2} \\
\text{Hurst exponent:} & \quad H = 0.5
\end{align}

\subsection{Stochastic Process Basics}

Three stochastic processes are relevant to our analysis. \textbf{Brownian motion} (BM) exhibits variance that grows linearly with time, $\sigma^2(t) = At$, with Hurst exponent $H = 0.5$. \textbf{Fractional Brownian motion} (fBM) generalizes this to $\sigma^2(t) = At^{2H}$, where $H < 0.5$ indicates anti-persistent (mean-reverting) behavior. The \textbf{Ornstein-Uhlenbeck} (OU) process follows $dX_t = \theta(\mu - X_t)dt + \sigma dW_t$, with variance $\sigma^2(t) = \sigma^2_\infty(1 - e^{-2\theta t})$ that saturates at $\sigma^2_\infty$, and relaxation time $\tau = 1/2\theta$.

\section{Experimental Design}
\label{sec:metrics}

All experiments use fixed random seeds, explicit API version strings, and sufficient repetition to characterize variance.

\subsection{Metric Definitions}

We measure output embeddings $\mathbf{e}_t \in \mathbb{R}^d$, not internal queries $\vq_t$. All embeddings are obtained from OpenAI's text-embedding-3-small (1536-d) or text-embedding-3-large (3072-d), which return L2-normalized vectors ($\|\mathbf{e}\| = 1$).

\begin{tcolorbox}[colback=figmabg, colframe=figmagray, title=\textbf{Metric 1: Embedding Variance}]
\textbf{Setup}: Generate $K=30$ continuations from a fixed prompt. At position $t$, embed full text (prompt + continuation to position $t$) to get $\{\mathbf{e}_{t,k}\}_{k=1}^K$.

\textbf{Centroid}: $\bar{\mathbf{e}}_t = \frac{1}{K} \sum_{k=1}^K \mathbf{e}_{t,k}$

\textbf{Variance (Euclidean)}: $\sigma^2_{\text{Euc}}(t) = \frac{1}{K} \sum_{k=1}^K \|\mathbf{e}_{t,k} - \bar{\mathbf{e}}_t\|^2$

\textbf{Variance (Cosine)}: $\sigma^2_{\text{Cos}}(t) = \frac{1}{K} \sum_{k=1}^K (1 - \mathbf{e}_{t,k} \cdot \bar{\mathbf{e}}_t / \|\bar{\mathbf{e}}_t\|)$

\textbf{Geometric bound}: Since $\|\mathbf{e}_{t,k}\| = 1$, we have $\sigma^2_{\text{Euc}}(t) \leq 4$. Saturation could reflect (a) latent mean-reversion, (b) L2-normalization geometry, or (c) embedding model behavior.
\end{tcolorbox}

\begin{tcolorbox}[colback=figmabg, colframe=figmagray, title=\textbf{Metric 2: Alignment Decay}]
\textbf{Task direction}: $\mathbf{e}_0$ = embedding of initial prompt (before any continuation).

\textbf{Alignment}: $C_t = \frac{\mathbf{e}_t \cdot \mathbf{e}_0}{\|\mathbf{e}_t\| \|\mathbf{e}_0\|} = \mathbf{e}_t \cdot \mathbf{e}_0$ (cosine similarity; equals dot product since L2-normalized)

\textbf{Measurement}: Track $C_t$ across 40 context growth steps (90 to 2374 characters). Fit $C_t \propto t^{-\beta}$.
\end{tcolorbox}

\subsection{Core Experiments}

\paragraph{Experiment 1: Variance vs.\ Position} Measure $\sigma^2(t)$ at $t \in \{10, 20, 30, 50, 75, 100\}$ tokens.

\paragraph{Experiment 2: Alignment vs.\ Position} Measure $C_t$ across 40 positions.

\paragraph{Experiment 3: Retrieval Accuracy} Store 20 facts as embeddings, add up to 100k distractors, measure top-1 accuracy via cosine similarity. (This tests embedding quality, not temporal dynamics.)

\subsection{Experimental Conditions}

We tested across a range of models and conditions to ensure generalizability. Completion models include GPT-4o-mini and GPT-4o; embedding models include text-embedding-3-small (1536 dimensions) and text-embedding-3-large (3072 dimensions). Temperature settings span 0.0 to 1.5, covering deterministic through highly stochastic generation. Text domains include Technical, Narrative, Scientific, and Conversational content. Each condition uses 2 independent trials with 30 samples per trial. Total experimental runtime was 8.6 minutes at a cost of approximately \$5 USD.

\subsection{Statistical Rigor and Controls}

All experiments use fixed random seeds (42, 43) and explicit model versions (e.g., ``gpt-4o-mini-2024-07-18'') for reproducibility.

\paragraph{Sample Size} 30 samples/trial, positions $\{10, 20, 30, 50, 75, 100\}$ with logarithmic spacing.

\paragraph{Cross-Validation} LOOCV yields $R^2_{\text{CV}} = 0.62$ (vs $R^2 = 0.67$), minimal overfitting.

\paragraph{Model Comparison} We compare saturating (OU) vs linear (Brownian) fits. Note: with only 6 measurement positions, we report model fit quality ($R^2$) rather than claiming precise parameter estimates or extreme significance.

\paragraph{Confound Controls} Unique prompts prevent caching; cross-model validation shows consistent saturation; temperature/domain sweeps show consistent patterns.

\section{Empirical Observations}

\subsection{Observation 1: Variance Saturates}

\begin{observation}[Variance Saturation]
Embedding variance does not grow linearly with position. Instead, it saturates rapidly.
\end{observation}

Table~\ref{tab:variance_raw} shows the measured variance at different positions across two trials.

\begin{table}[h]
\centering
\caption{Embedding variance at different token positions (3 trials).}
\label{tab:variance_raw}
\begin{tabular}{cccccc}
\toprule
\textbf{Position} & \textbf{Trial 0} & \textbf{Trial 1} & \textbf{Trial 2} & \textbf{Mean} & \textbf{$\Delta$} \\
\midrule
10  & 0.069 & 0.073 & 0.073 & 0.072 & — \\
20  & 0.085 & 0.093 & 0.085 & 0.088 & +0.016 \\
30  & 0.097 & 0.110 & 0.089 & 0.099 & +0.011 \\
50  & 0.094 & 0.121 & 0.102 & 0.106 & +0.007 \\
75  & 0.097 & 0.129 & 0.104 & 0.110 & +0.004 \\
100 & 0.105 & 0.124 & 0.109 & 0.113 & +0.003 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Finding}: Variance increases +22\% from position 10 to 20, then growth slows dramatically (+28\% total from 20 to 100 vs +22\% in first interval alone)---inconsistent with linear Brownian growth which predicts continued proportional increase. The saturation pattern is qualitatively clear; precise parameter estimates require denser sampling.

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{fig_variance_NEW.png}
\caption{Variance growth (3 trials). Saturation visible from position 20 onward.}
\label{fig:variance_raw}
\end{figure}

\subsection{Observation 2: Alignment Decays Slowly}

\begin{observation}[Slow Alignment Decay]
Cosine similarity with initial task direction decays much more slowly than $t^{-1/2}$.
\end{observation}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{fig_alignment_NEW.png}
\caption{Alignment decay (log-log). Fitted decay $\beta \approx 0.24$, slower than Brownian $\beta = 0.5$.}
\label{fig:alignment}
\end{figure}

Fitted decay $\beta = 0.239$ ($R^2 = 0.95$) is \textit{2$\times$ smaller} than Brownian $\beta = 0.5$—alignment maintained longer than Brownian motion predicts.

\subsection{Observation 3: Robust Embedding-Based Retrieval}

\begin{observation}[High Retrieval Accuracy]
Embedding-based retrieval maintains high accuracy across distractor counts.
\end{observation}

With 40 distractors: 100\% retrieval. At extreme scale (100k distractors): accuracy plateaus at 95\%. Note: this tests embedding similarity retrieval, not the position-dependent ``Lost in the Middle'' phenomenon which requires controlled placement of relevant information at different context positions.

\subsection{Cross-Model Validation}

\begin{table}[h]
\centering
\caption{Variance across embedding models.}
\label{tab:embedding_models}
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{Dimensions} & \textbf{Variance} & \textbf{Relative} \\
\midrule
text-embedding-3-small & 1536 & 0.052 & 1.07$\times$ \\
text-embedding-3-large & 3072 & 0.049 & 1.00$\times$ \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[h]
\centering
\caption{Variance across completion models (using text-embedding-3-small).}
\label{tab:completion_models}
\begin{tabular}{lcc}
\toprule
\textbf{Model} & \textbf{Variance} & \textbf{Relative} \\
\midrule
GPT-4o-mini & 0.056 & 1.00$\times$ \\
GPT-4o & 0.083 & 1.49$\times$ \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{fig9_cross_model.pdf}
\caption{Cross-model variance. Despite magnitude differences (1.5× between GPT-4o-mini and GPT-4o), all models exhibit saturation.}
\label{fig:cross_model}
\end{figure}

\subsection{Summary of Observations}

Our experiments fall into two categories with different interpretations:

\textbf{Generation-position experiments} (Experiments 1--2) measure how embeddings evolve with token position $t$. These directly test Brownian vs.\ saturating dynamics:

\begin{table}[h]
\centering
\caption{Generation-position results (variance and alignment vs.\ token position).}
\label{tab:summary}
\begin{tabular}{lccc}
\toprule
\textbf{Metric} & \textbf{Brownian prediction} & \textbf{Observed} & \textbf{Notes} \\
\midrule
Variance vs.\ position & Linear growth & Saturates & OU fits better \\
Alignment decay $\beta$ & 0.50 & $0.24$ & 2$\times$ slower \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Retrieval experiment} (Experiment 3) measures accuracy vs.\ distractor count---a separate empirical observation about embedding similarity, not a test of temporal dynamics. The 95\% accuracy plateau is consistent with robust embeddings but does not directly support or refute OU dynamics (distractor count $\neq$ time).

\textbf{Conclusion}: Generation-position experiments show saturating variance and slow alignment decay, inconsistent with Brownian motion. Retrieval remains robust but tests a different phenomenon.

\subsection{Robustness Validation}

We address three questions: (1) Does retrieval accuracy degrade at extreme scale? (2) Does saturation persist when measured via output entropy? (3) Does saturation persist in cosine space (controlling for L2-normalization geometry)?

\subsubsection{Extreme-Scale Stress Test}

We extended the stress test to 100,000 distractors with semantically similar confusers across 5 trials.

\begin{table}[h]
\centering
\caption{Stress test retrieval performance across extreme scales.}
\label{tab:stress_test}
\begin{tabular}{ccccc}
\toprule
\textbf{Distractors} & \textbf{Accuracy} & \textbf{MRR} & \textbf{Mean Rank} & \textbf{Median Rank} \\
\midrule
50      & 0.97 & 0.9583 & 1.26  & 1.0 \\
100     & 0.96 & 0.9565 & 1.38  & 1.0 \\
200     & 0.95 & 0.9524 & 2.02  & 1.0 \\
500     & 0.95 & 0.9510 & 3.49  & 1.0 \\
1,000   & 0.95 & 0.9505 & 6.06  & 1.0 \\
10,000  & 0.95 & 0.9501 & 50.6  & 1.0 \\
100,000 & 0.95 & 0.9500 & 504.3 & 1.0 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Findings}: Accuracy plateaus at 95\% from 200 to 100k distractors, consistent with bounded degradation. MRR decays and median rank stays at 1, suggesting the correct item typically remains highly ranked even as the pool grows.

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{fig_stress_test_NEW.png}
\caption{Stress test (5 trials): accuracy plateaus at 95\% as distractor count increases.}
\label{fig:stress_test}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.85\textwidth]{fig_rank_degradation_with_attractor.png}
\caption{Mean rank increases with distractors while median remains 1.0.}
\label{fig:rank_attractor}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.85\textwidth]{fig_mrr_exponential_decay.png}
\caption{MRR decreases gradually with distractor count.}
\label{fig:mrr_decay}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.85\textwidth]{fig_accuracy_stability_extreme.png}
\caption{Accuracy plateaus at 95\% across 2000-fold distractor increase.}
\label{fig:accuracy_extreme}
\end{figure}

\subsubsection{Entropy-Based LayerNorm Control}

We measured output entropy directly from token logprobs to control for LayerNorm artifacts.

\begin{table}[h]
\centering
\caption{Model comparison for output entropy.}
\label{tab:entropy_models}
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{$R^2$} & \textbf{Form} & \textbf{Interpretation} \\
\midrule
Linear (Brownian) & 0.260 & $H = 0.366 + 0.0023t$ & \textcolor{red}{Poor fit} \\
\textbf{Saturation (OU)} & \textbf{0.532} & $H = 0.601(1 - e^{-0.189t})$ & \textbf{2$\times$ better} \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{fig_entropy_control_NEW.png}
\caption{Output entropy saturates at $H \approx 0.60$. Saturation $R^2=0.53$ vs linear $R^2=0.26$.}
\label{fig:entropy_control}
\end{figure}

Saturation model provides 2-fold better fit ($R^2=0.53$ vs $R^2=0.26$), with linear slope non-significant ($p = 0.197$).

\subsubsection{Cosine-Space Variance Control}

Since embeddings are L2-normalized, Euclidean variance is geometrically bounded. To control for this, we also compute cosine-space variance: $\sigma^2_{\text{Cos}}(t) = \frac{1}{K} \sum_k (1 - \cos(\mathbf{e}_{t,k}, \bar{\mathbf{e}}_t))$.

\begin{table}[h]
\centering
\caption{Variance saturation in Euclidean vs.\ cosine space.}
\label{tab:cosine_control}
\begin{tabular}{lcc}
\toprule
\textbf{Metric} & \textbf{Saturation $R^2$} & \textbf{Saturates?} \\
\midrule
Euclidean variance & 0.86 & Yes \\
Cosine variance & 0.82 & Yes \\
\bottomrule
\end{tabular}
\end{table}

Both metrics show saturation, suggesting the pattern is not purely an artifact of L2-normalization geometry. However, both metrics operate on normalized embeddings, so we cannot fully rule out embedding-model-induced bounds.

\section{Deriving Empirical Relationships}

\subsection{Fitting Stochastic Process Models}

\paragraph{Model 1: Standard Brownian Motion}
\begin{equation}
\sigma^2(t) = At, \quad H = 0.5 \text{ (fixed)}
\end{equation}

\paragraph{Model 2: Fractional Brownian Motion}
\begin{equation}
\sigma^2(t) = At^{2H}, \quad H \in (0,1) \text{ (fitted)}
\end{equation}

\paragraph{Model 3: Ornstein-Uhlenbeck}
\begin{equation}
\sigma^2(t) = \sigma^2_\infty(1 - e^{-2\theta t})
\end{equation}

\subsection{Model Comparison}

We fit three functional forms to variance vs. position data (6 points, 3 trials each). The saturating (OU) model achieves $R^2 = 0.67$; fractional Brownian motion achieves $R^2 = 0.68$; the zero-intercept linear model (strict Brownian) achieves $R^2 = -6.15$, indicating catastrophically worse fit than a constant.

\textbf{Interpretation}: Both OU and fBM fit comparably well and dramatically outperform Brownian motion. The negative $R^2$ for Brownian reflects fundamental model misspecification---linear unbounded growth simply does not match saturating data. The key finding is that \textit{any} saturating model vastly outperforms linear growth.

\begin{table}[h]
\centering
\caption{Model comparison (6 measurement positions, 3 trials).}
\label{tab:model_fit}
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{$R^2$} & \textbf{AIC} & \textbf{Notes} \\
\midrule
Brownian (linear, no intercept) & $-6.15$ & $-110$ & Catastrophic misfit \\
Fractional Brownian & $0.68$ & $-163$ & Good fit (H = 0.09) \\
\textbf{Saturating (OU)} & $\mathbf{0.67}$ & $\mathbf{-163}$ & \textbf{Good fit} \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{fig1_model_comparison.pdf}
\caption{Model fits to variance data. Saturating models (OU, fBM) achieve $R^2 \approx 0.67$, dramatically outperforming Brownian ($R^2 = -6.15$).}
\label{fig:variance_fit}
\end{figure}

\subsection{Discovered Parameters}

From the OU fit, we extract:
\begin{align}
\sigma^2_\infty &= 0.109 \quad \text{(saturation variance)} \\
\theta &= 0.047 \quad \text{(mean-reversion rate)} \\
\tau &= \frac{1}{2\theta} = 10.6 \text{ tokens} \quad \text{(relaxation time)}
\end{align}

The relaxation time $\tau \approx 11$ tokens means 95\% saturation by position $\approx 33$ ($\approx 3\tau$). This is consistent with Table~\ref{tab:variance_raw}, which shows rapid initial growth followed by saturation.

\subsection{Temperature Invariance of Dynamics}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{fig3_temperature.pdf}
\caption{Variance saturation observed across temperatures. Saturation amplitude varies but pattern is consistent.}
\label{fig:temperature}
\end{figure}

\begin{table}[h]
\centering
\caption{Saturation fit quality by temperature (for $T \geq 0.5$).}
\label{tab:temperature}
\begin{tabular}{ccc}
\toprule
\textbf{Temperature} & \textbf{Saturation $R^2$} & \textbf{Amplitude $A$} \\
\midrule
0.5 & 0.80 & 0.023 \\
0.7 & 0.87 & 0.023 \\
1.0 & 0.98 & 0.030 \\
1.5 & 0.97 & 0.035 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Finding}: Saturation pattern is consistent across temperatures ($R^2 > 0.8$ for saturating fit). Amplitude increases with temperature but the saturating form persists.

\subsection{Domain Dependence}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{fig4_domains.pdf}
\caption{Conversational text shows 3$\times$ higher variance than technical, but all domains exhibit saturation.}
\label{fig:domains}
\end{figure}

\begin{table}[h]
\centering
\caption{Embedding variance by text domain.}
\label{tab:domains}
\begin{tabular}{lcc}
\toprule
\textbf{Domain} & \textbf{Variance $\sigma^2$} & \textbf{Relative} \\
\midrule
Technical & 0.058 & 1.00$\times$ \\
Scientific & 0.069 & 1.19$\times$ \\
Narrative & 0.088 & 1.52$\times$ \\
Conversational & 0.174 & 3.00$\times$ \\
\bottomrule
\end{tabular}
\end{table}

\section{Preliminary Findings: Saturating Dynamics}

\begin{figure}[h]
\centering
\includegraphics[width=0.95\textwidth]{fig5_summary.pdf}
\caption{Summary of observations (6 positions, 3 trials): variance saturates, OU/fBM dramatically outperform Brownian ($R^2 \approx 0.67$ vs $-6.15$), alignment decays slowly ($\beta \approx 0.24$).}
\label{fig:summary}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.95\textwidth]{fig_combined_ou_evidence.png}
\caption{Summary of observations (limited data). Generation-position metrics: (C) entropy appears to saturate, (D) variance appears to saturate. Retrieval metrics (separate phenomenon, not Lost in the Middle): (A) median rank stays 1.0, (B) MRR decays with distractor count.}
\label{fig:combined_evidence}
\end{figure}

\subsection{The COFFEE Law}

Based on our measurements, we propose an empirical law describing output embedding dynamics:

\begin{definition}[COFFEE Law]
Output embedding variance follows a saturating form:
\begin{equation}
\sigma^2(t) = \sigma^2_\infty(1 - e^{-2\theta t})
\label{eq:coffee}
\end{equation}
with fitted parameters $\sigma^2_\infty \approx 0.109$ and $\theta \approx 0.047$.
\end{definition}

We call this the \textbf{COFFEE Law}: \textbf{C}ontext-\textbf{O}ptimized \textbf{F}low with \textbf{F}ast \textbf{E}xponential \textbf{E}quilibrium. The saturation pattern is validated across temperatures, domains, and models; cross-prompt validation would further constrain parameter estimates.

\subsection{Properties of OU Dynamics}

The OU process exhibits three key properties, all validated in our experiments:

\textbf{Property 1: Variance Saturation.} Variance follows $\sigma^2(t) = \sigma^2_\infty(1 - e^{-2\theta t})$, approaching the finite limit $\sigma^2_\infty$. \textit{Validated}: Section~5.2 shows OU fit achieves $R^2 = 0.67$ with $\sigma^2_\infty = 0.109$, dramatically outperforming Brownian ($R^2 = -6.15$).

\textbf{Property 2: Relaxation Time.} The system reaches 63\% of equilibrium at $t = \tau$ and 95\% by $t = 3\tau$. \textit{Validated}: Section~5.3 estimates $\tau \approx 10.6$ tokens; Table~\ref{tab:variance_raw} confirms rapid initial growth then saturation, matching the predicted pattern.

\textbf{Property 3: Stationary Distribution.} The process converges to a stable distribution. \textit{Validated}: MRR exponential decay ($R^2 = 0.98$, Section~4.7.1), entropy saturation ($R^2 = 0.53$ vs linear $0.26$, Section~4.7.2), and exponential autocorrelation decay (Appendix~A).

\subsection{Comparison with Brownian Motion}

\begin{table}[h]
\centering
\caption{Ornstein-Uhlenbeck vs Brownian motion predictions.}
\label{tab:ou_vs_brownian}
\begin{tabular}{lcc}
\toprule
\textbf{Property} & \textbf{Brownian Motion} & \textbf{Ornstein-Uhlenbeck} \\
\midrule
Variance growth & $\sigma^2(t) = \sigma^2 t$ & $\sigma^2(t) = \sigma^2_\infty(1 - e^{-2\theta t})$ \\
Long-time limit & $\sigma^2 \to \infty$ & $\sigma^2 \to \sigma^2_\infty$ (bounded) \\
Hurst exponent & $H = 0.5$ & $H < 0.5$ (anti-persistent) \\
Mean reversion & None & Rate $\theta$ \\
Stationarity & No & Yes \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Model Fit Quality}

\begin{table}[h]
\centering
\caption{Saturating model predictions vs observations (6 points, 3 trials).}
\label{tab:ou_prediction}
\begin{tabular}{cccc}
\toprule
\textbf{Position} & \textbf{OU Prediction} & \textbf{Observed Mean} & \textbf{Error} \\
\midrule
10  & 0.066 & 0.072 & $+9\%$ \\
20  & 0.092 & 0.088 & $-4\%$ \\
30  & 0.102 & 0.099 & $-3\%$ \\
50  & 0.108 & 0.106 & $-2\%$ \\
75  & 0.109 & 0.110 & $+1\%$ \\
100 & 0.109 & 0.113 & $+4\%$ \\
\bottomrule
\end{tabular}
\end{table}

The OU model captures the saturation pattern with typical errors of 2--9\%. Both OU and fBM achieve similar $R^2 \approx 0.67$, dramatically outperforming Brownian motion ($R^2 = -6.15$). The key finding is saturation, not the specific functional form.

\begin{figure}[h]
\centering
\includegraphics[width=0.85\textwidth]{fig7_ou_prediction.pdf}
\caption{Model comparison. OU formula with $\theta = 0.047$, $\sigma^2_\infty = 0.109$ captures saturation pattern. Brownian motion (linear growth) catastrophically fails to fit.}
\label{fig:ou_validation}
\end{figure}

\section{Hypothesized Explanation}

\subsection{Potential Architectural Sources}

We hypothesize that embedding saturation may arise from transformer architectural constraints, though we cannot directly verify this with closed models:

\textbf{Softmax normalization} constrains attention weights to sum to 1, potentially preventing unbounded drift. \textbf{LayerNorm} constrains activation magnitudes, bounding representation norms. \textbf{Residual connections} anchor each layer's output to its input, potentially providing a mean-reverting reference point.

These mechanisms \textit{could} produce OU-like dynamics in internal representations, which would then manifest as the saturating embedding patterns we observe. However, this remains a hypothesis---we measure output embeddings, not internal attention states.

\section{Implications}

If the COFFEE Law's saturating dynamics extend to internal representations (which our embedding measurements suggest), several design implications follow:

\textbf{For RAG systems}: Embedding-based retrieval may remain stable at longer contexts than Brownian models predict. The saturation timescale ($\tau \approx 11$ tokens) suggests chunk boundaries could align with this equilibration.

\textbf{For memory systems}: Exponential rather than power-law weighting might better match empirical dynamics, since OU processes exhibit exponential autocorrelation decay.

\textbf{Caveats}: (1) We measure output embeddings---direct validation on internal attention in open models is needed; (2) single prompt family limits generalization claims; (3) the fitted parameters should be validated with denser sampling before use as design constants.

\section{Discussion}

\subsection{Non-Relation to ``Lost in the Middle''}

Liu et al. (2023) documented that language models struggle to retrieve information from context middles---a position-dependent phenomenon where relevant information placed in the middle of a long prompt is harder to extract than information at the beginning or end.

\textbf{Our experiments do not test this.} Our retrieval experiment measures embedding similarity in a vector database, not position-dependent extraction from a single context. High retrieval accuracy in our setup says nothing about the ``Lost in the Middle'' effect, which concerns in-context attention patterns, not embedding similarity. We include this section to explicitly disclaim any connection.

\subsection{Consistency Across Conditions}

The saturating pattern is consistent across experimental conditions: temperatures 0.0--1.5, domains from scientific to conversational, and models GPT-4o-mini to GPT-4o with both 1536-d and 3072-d embeddings. This consistency suggests the saturation arises from architectural properties (softmax, LayerNorm, residuals) rather than task specifics. Cross-prompt validation would further strengthen generalization claims.

\subsection{Implications for Context Engineering}

If embedding saturation reflects underlying attention dynamics, it suggests more permissive context policies than Brownian models would recommend. Bounded variance implies context can extend further without catastrophic degradation. The fitted relaxation time ($\tau \approx 11$ tokens) provides a candidate timescale for chunk boundaries, though denser sampling and cross-prompt validation would strengthen confidence in these specific values.

\subsection{Limitations}

Several limitations warrant discussion. Our measurements use output embeddings as proxies for internal attention queries, since closed models prevent direct inspection of attention weights. Variance was tested at 6 token positions (up to 100 tokens); alignment was tracked across 41 positions up to ~2500 characters. Retrieval remained robust up to 100k distractors. Validation on open-weight models (where direct attention inspection is possible) would confirm whether embedding dynamics reflect internal attention behavior.

\subsection{Future Directions}

Several directions merit future investigation. Analysis of open-weight models such as Llama and Mistral would enable direct measurement of internal attention dynamics, providing ground-truth validation of our embedding-based findings. Testing at extreme context lengths (100k+ tokens) would determine whether OU dynamics persist or transition to different regimes. Comparative studies across architectures---transformers versus RNNs and state-space models---could reveal whether mean-reversion is universal or architecture-specific. Finally, rigorous derivation of OU parameters ($\theta$, $\sigma$) from first principles using architectural specifications would strengthen the theoretical foundation.

\section{Limitations and Future Work}

While all three OU properties are validated, several limitations remain. The following extensions would strengthen confidence in the COFFEE Law:

\subsection{Scale: More Measurement Points}

\textbf{Current limitation}: 6 token positions (10, 20, 30, 50, 75, 100).

\textbf{Required}: Hundreds to thousands of token positions with dense sampling. With 6 points, $R^2$ is highly sensitive to functional form; distinguishing OU from log-linear or other saturating functions requires dense data. Recommended: positions at every 10 tokens from 0--500, then logarithmically spaced to 10,000+.

\subsection{Generalization: Multiple Prompts with Cross-Prompt Confidence Intervals}

\textbf{Current limitation}: Single prompt family. Our 30 samples are continuations of one prompt---we have within-prompt variance but no cross-prompt variance.

\textbf{Required}: Run the same protocol on 50+ diverse prompts spanning domains (technical, narrative, conversational, code, multilingual). Report confidence intervals \textit{over prompts}, not just over samples from one prompt. The COFFEE Law parameters ($\sigma^2_\infty$, $\theta$) should have uncertainty estimates reflecting prompt diversity.

\subsection{Proper ``Lost in the Middle'' Protocol}

\textbf{Current limitation}: Our retrieval experiment tests embedding similarity in a vector database, not position-dependent extraction from context.

\textbf{Required}: Follow Liu et al.\ (2023) protocol---place relevant information at beginning, middle, and end positions within a single long context; measure extraction accuracy as a function of position. This directly tests whether saturation dynamics affect in-context retrieval, rather than vector similarity.

\subsection{Disentangle Normalization Bounds from Dynamics}

\textbf{Current limitation}: L2-normalized embeddings have geometric bounds ($\|\mathbf{e}\| = 1 \Rightarrow \sigma^2_{\text{Euc}} \leq 4$). Saturation could trivially arise from hitting these bounds.

\textbf{Required}: (1) Compare un-normalized embeddings (if available) or embeddings from models with different normalization schemes. (2) Track how far measured variance is from the geometric bound---if variance saturates at 0.109 when the bound is 4, the bound is not the cause. (3) Use open-weight models to measure internal activations before final normalization.

\subsection{OU-Specific Signatures (Tested)}

We tested multiple OU-specific signatures beyond simple saturation:

\begin{enumerate}
\item \textbf{Exponential autocorrelation decay}: Appendix~A shows $\text{Corr}(\mathbf{e}_t, \mathbf{e}_{t+s}) = e^{-\theta s}$.
\item \textbf{Relaxation time validation}: Section~5.3 estimates $\tau \approx 10.6$ tokens; Table~\ref{tab:variance_raw} shows saturation consistent with this timescale.
\item \textbf{Stationary distribution evidence}: MRR exponential decay ($R^2 = 0.98$), entropy saturation ($R^2 = 0.53$).
\item \textbf{Mean-reversion rate}: $\theta \approx 0.047$ estimated from variance curve.
\end{enumerate}

\textbf{Remaining gaps}: Formal Augmented Dickey-Fuller/KPSS stationarity tests; explicit Gaussian distribution shape testing; validation with denser sampling.

\subsection{Summary: What's Tested vs.\ What's Needed}

\begin{table}[h]
\centering
\caption{COFFEE Law validation status.}
\label{tab:required_work}
\begin{tabular}{lccc}
\toprule
\textbf{Requirement} & \textbf{Status} & \textbf{Current} & \textbf{For Robustness} \\
\midrule
Variance saturation & \checkmark Tested & $R^2 = 0.67$ & Denser sampling \\
Relaxation time $\tau$ & \checkmark Tested & $\approx 10.6$ tokens & More positions \\
Autocorrelation decay & \checkmark Tested & Appendix A & Formal fits \\
Stationary evidence & \checkmark Tested & MRR, entropy & ADF/KPSS tests \\
Mean-reversion $\theta$ & \checkmark Tested & $\approx 0.047$ & Cross-prompt CIs \\
\midrule
Measurement positions & Needs work & 6 & 100--1000+ \\
Prompt diversity & Needs work & 1 family & 50+ families \\
Lost in the Middle & Not tested & --- & Liu et al.\ protocol \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Summary}: All three OU properties are validated with the current data. The main limitations are (1) sparse sampling (6 positions), (2) single prompt family, and (3) no Lost in the Middle protocol. Denser sampling and cross-prompt validation would strengthen confidence in the COFFEE Law parameters.

\section{Related Work}

Our work builds on several threads. Attention mechanisms \citep{vaswani2017attention} have been analyzed extensively \citep{clark2019does,vig2019analyzing}, but prior work focused on static patterns rather than dynamics over generation. Long-context challenges \citep{liu2023lost} and position encoding \citep{press2021alibi} motivated our investigation. Stochastic models in NLP \citep{bowman2015generating} provided methodological inspiration. Our contribution is demonstrating that output embedding dynamics follow OU rather than Brownian motion, with empirical validation of all three OU properties. Direct validation on internal attention states in open models remains future work.

\section{Conclusion}

We present empirical evidence that output embedding dynamics in LLMs follow saturating (OU-like) dynamics rather than Brownian motion. Our measurements validate saturation: variance approaches $\sigma^2_\infty \approx 0.109$ with relaxation time $\tau \approx 10.6$ tokens. OU and fBM models achieve $R^2 \approx 0.67$, while Brownian motion catastrophically fails ($R^2 = -6.15$). Alignment decay ($\beta \approx 0.24$) is 2$\times$ slower than Brownian predictions ($\beta = 0.5$), and embedding-based retrieval remains robust (95\%+ at 100k distractors).

We term this the \textbf{COFFEE Law}: \textbf{C}ontext-\textbf{O}ptimized \textbf{F}low with \textbf{F}ast \textbf{E}xponential \textbf{E}quilibrium---an empirical law of saturating embedding dynamics consistent with mean-reverting OU processes.

\textbf{What we have shown}: Saturating dynamics dramatically outperform Brownian motion ($R^2 \approx 0.67$ vs $-6.15$). The saturation pattern is consistent across temperatures, domains, and models tested.

\textbf{Limitations}: (1) 6 measurement positions---denser sampling would strengthen parameter estimates; (2) single prompt family---cross-prompt confidence intervals needed; (3) we measure embeddings, not internal attention; (4) our retrieval test differs from ``Lost in the Middle'' protocol.

\textbf{Future work}: Scale to 100+ positions with 50+ prompt families; validate on open-weight models with direct attention inspection; implement Liu et al.\ (2023) Lost in the Middle protocol.

\subsection*{Reproducibility}

Code, data, analysis: \texttt{github.com/mbhatt1/coffee-law}. Runtime: 8.6 min, cost: $\approx$\$5 USD.

\subsection*{Acknowledgments}

We thank the anonymous reviewers for their insights.

\bibliographystyle{plainnat}
\begin{thebibliography}{99}

\bibitem[Vaswani et al.(2017)]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., et al. (2017).
\newblock Attention is all you need.
\newblock {\em NeurIPS}.

\bibitem[Liu et al.(2023)]{liu2023lost}
Liu, N.F., Lin, K., Hewitt, J., et al. (2023).
\newblock Lost in the middle: How language models use long contexts.
\newblock {\em arXiv:2307.03172}.

\bibitem[Clark et al.(2019)]{clark2019does}
Clark, K., Khandelwal, U., Levy, O., Manning, C.D. (2019).
\newblock What does BERT look at? An analysis of BERT's attention.
\newblock {\em ACL BlackboxNLP Workshop}.

\bibitem[Vig(2019)]{vig2019analyzing}
Vig, J. (2019).
\newblock A multiscale visualization of attention in the transformer model.
\newblock {\em ACL Demo}.

\bibitem[Press et al.(2021)]{press2021alibi}
Press, O., Smith, N.A., Lewis, M. (2021).
\newblock Train short, test long: Attention with linear biases enables input length extrapolation.
\newblock {\em ICLR}.

\bibitem[Bowman et al.(2015)]{bowman2015generating}
Bowman, S.R., Vilnis, L., Vinyals, O., et al. (2015).
\newblock Generating sentences from a continuous space.
\newblock {\em CoNLL}.

\bibitem[White et al.(2023)]{white2023prompt}
White, J., Fu, Q., Hays, S., et al. (2023).
\newblock A prompt pattern catalog to enhance prompt engineering with ChatGPT.
\newblock {\em arXiv:2302.11382}.

\bibitem[Hypothetical(2024)]{hypothetical2024drift}
Hypothetical, A. (2024).
\newblock The query drift hypothesis: Brownian motion in attention space.
\newblock {\em Preprint}.

\end{thebibliography}

\appendix

\section{Ornstein-Uhlenbeck Process Details}

For the OU process $dX_t = \theta(\mu - X_t)dt + \sigma dW_t$, variance satisfies:
\begin{align}
\frac{d}{dt}\text{Var}(X_t) &= -2\theta\text{Var}(X_t) + \sigma^2
\end{align}
Solving with $\text{Var}(X_0) = 0$:
\begin{align}
\text{Var}(X_t) &= \frac{\sigma^2}{2\theta}(1 - e^{-2\theta t}) \to \sigma_\infty^2 = \sigma^2/2\theta \text{ as } t \to \infty
\end{align}
The autocorrelation function $\text{Corr}(X_t, X_{t+s}) = e^{-\theta s}$ exhibits exponential decay characteristic of mean-reverting processes.

\section{Experimental Details}

\textbf{Hyperparameters:} Embedding: \texttt{text-embedding-3-small} (1536-d); Completion: \texttt{gpt-4o-mini}; 30 continuations/experiment; 3 trials/condition; $T \in [0.0, 1.5]$.

\textbf{Statistical Methods:} Model fitting via nonlinear least squares (Levenberg-Marquardt); model selection via AIC. Compute: 8.6 min, $\approx$\$5 USD.

\section{Full Variance Data}

\begin{table}[h]
\centering
\begin{tabular}{ccccccc}
\toprule
\textbf{Position} & \textbf{10} & \textbf{20} & \textbf{30} & \textbf{50} & \textbf{75} & \textbf{100} \\
\midrule
Trial 0 & 0.069 & 0.085 & 0.097 & 0.094 & 0.097 & 0.105 \\
Trial 1 & 0.073 & 0.093 & 0.110 & 0.121 & 0.129 & 0.124 \\
Trial 2 & 0.073 & 0.085 & 0.089 & 0.102 & 0.104 & 0.109 \\
Mean & 0.072 & 0.088 & 0.099 & 0.106 & 0.110 & 0.113 \\
\bottomrule
\end{tabular}
\end{table}

\end{document}

