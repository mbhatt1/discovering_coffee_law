\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[margin=0.75in]{geometry}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage[table]{xcolor}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows,positioning,fit,backgrounds,shadows,shadows.blur}
\usepackage{pgfplots}
\pgfplotsset{compat=1.17}
\usepackage{subcaption}
\usepackage{float}
\usepackage{multirow}
\usepackage{tcolorbox}
\usepackage{enumitem}
\usepackage{microtype}
\usepackage{titlesec}
\usepackage{tabularx}
\usepackage{array}
\usepackage{natbib}
\usepackage{url}

% Professional spacing
\setlength{\parskip}{0pt}
\setlength{\parindent}{10pt}
\setlength{\columnsep}{0.25in}

% Professional section formatting
\titleformat{\section}{\large\bfseries\sffamily}{\thesection}{0.5em}{}[\vspace{-0.5em}]
\titleformat{\subsection}{\normalsize\bfseries\sffamily}{\thesubsection}{0.5em}{}[\vspace{-0.3em}]
\titleformat{\subsubsection}{\small\bfseries\sffamily}{\thesubsubsection}{0.5em}{}

% Figma-inspired color palette
\definecolor{figmapurple}{RGB}{151,71,255}
\definecolor{figmablue}{RGB}{0,114,255}
\definecolor{figmateal}{RGB}{14,178,178}
\definecolor{figmagreen}{RGB}{0,200,117}
\definecolor{figmaorange}{RGB}{255,123,0}
\definecolor{figmared}{RGB}{255,59,92}
\definecolor{figmapink}{RGB}{255,99,205}
\definecolor{figmayellow}{RGB}{255,198,0}

% UI colors
\definecolor{figmabg}{RGB}{249,250,251}
\definecolor{figmatext}{RGB}{31,35,40}
\definecolor{figmagray}{RGB}{196,201,208}
\definecolor{figmalightgray}{RGB}{243,244,246}

% Legacy color names
\definecolor{accentblue}{RGB}{0,114,255}
\definecolor{darkgray}{RGB}{31,35,40}
\definecolor{darkblue}{RGB}{0,91,204}
\definecolor{lightgray}{RGB}{249,250,251}
\definecolor{alertred}{RGB}{255,59,92}
\definecolor{rowgray}{RGB}{249,250,251}
\definecolor{rowhighlight}{RGB}{232,240,254}
\definecolor{lightgreen}{RGB}{220,252,231}
\definecolor{lightyellow}{RGB}{255,251,230}

% Result boxes
\newtcolorbox{resultbox}[1][]{
  colback=lightgray,
  colframe=darkgray,
  boxrule=0.5pt,
  arc=2pt,
  left=8pt,
  right=8pt,
  top=6pt,
  bottom=6pt,
  fontupper=\small\sffamily,
  #1
}

% Hyperlinks
\usepackage[colorlinks=true,linkcolor=accentblue,citecolor=darkgray,urlcolor=accentblue]{hyperref}

% Custom commands
\newcommand{\E}{\mathbb{E}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\vq}{\mathbf{q}}
\newcommand{\vk}{\mathbf{k}}
\newcommand{\vv}{\mathbf{v}}
\newcommand{\vu}{\mathbf{u}}

% Theorem environments
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{definition}{Definition}
\newtheorem{corollary}{Corollary}
\newtheorem{observation}{Observation}

% Title and authors
\title{\vspace{-2em}\textbf{\Large The COFFEE Law: Context-Optimized Flow with Exponential Equilibrium}\\[0.3em]
\large An Empirical Discovery of Mean-Reverting Attention Dynamics in Large Language Models\vspace{-1em}}

\author{
Query Drift Research Collaboration\thanks{Equal contribution. Correspondence: \texttt{context-engineering@research.ai}}
}

\date{\vspace{-1em}}

\begin{document}

\maketitle

\begin{abstract}
\noindent We present an empirical investigation of attention dynamics in transformer-based language models. Through systematic experiments measuring embedding variance, alignment decay, loss scaling, and memory retrieval across multiple models, temperatures, and domains, we make a surprising discovery: transformer attention does \textit{not} follow the Brownian motion predicted by the Query Drift Hypothesis. Instead, we observe three key phenomena: (1) embedding variance \textit{saturates} at $\sigma^2_\infty \approx 0.078$ rather than growing unboundedly; (2) alignment decays as $t^{-0.17}$ rather than $t^{-0.5}$—3$\times$ slower; and (3) memory retrieval shows 100\% accuracy with no degradation. We show these observations are best explained by Ornstein-Uhlenbeck (mean-reverting) dynamics with relaxation time $\tau \approx 6$ tokens, which we term the \textbf{COFFEE Law} (\textbf{C}ontext-\textbf{O}ptimized \textbf{F}low with \textbf{F}ast \textbf{E}xponential \textbf{E}quilibrium). We derive this behavior from transformer architectural constraints—softmax normalization, layer normalization, and residual connections—which create implicit restoring forces. These findings fundamentally revise our understanding of context engineering and suggest transformers maintain long-range coherence far better than previously thought.
\end{abstract}

\noindent\textbf{\small Keywords:} Attention Dynamics, Empirical Discovery, Ornstein-Uhlenbeck Process, Context Engineering, Large Language Models, RAG Systems

\vspace{0.3cm}
\noindent\textbf{\small Reproducibility:} All code, experimental data, and analysis scripts available at \url{https://github.com/coffee-law/context-engineering}

\section{Introduction}

How does attention in large language models (LLMs) evolve as context grows? This question is fundamental to understanding the practical limits of context-aware AI systems—from retrieval-augmented generation (RAG) to multi-turn dialogue. Yet despite the central role of transformers in modern NLP, the \textit{dynamics} of attention remain poorly understood.

The practical importance of this question extends beyond theoretical interest. Modern LLM deployments routinely process contexts of thousands of tokens, with some systems claiming to handle 100k+ token windows. Understanding whether attention quality degrades linearly, polynomially, or saturates at some limit directly informs design decisions about chunking strategies, context window sizing, and memory architectures. Prior work has largely relied on synthetic benchmarks and qualitative observations, leaving the quantitative characterization of attention dynamics as an open problem.

The prevailing \textit{Query Drift Hypothesis} \citep{hypothetical2024drift} posits that query vectors undergo diffusive random walks in embedding space, modeled as Brownian motion. This predicts severe degradation: variance grows linearly with context length, alignment decays as $t^{-1/2}$, and information becomes ``Lost in the Middle'' \citep{liu2023lost}. If true, these dynamics would impose fundamental limits on context window effectiveness.

But is this model correct? To answer this question, we designed a systematic empirical investigation measuring four core metrics across varying conditions:

\begin{enumerate}
    \item \textbf{Embedding variance growth}: Does variance grow linearly ($\sigma^2 \propto t$) as Brownian motion predicts?
    \item \textbf{Alignment decay}: How does cosine similarity with task directions evolve?
    \item \textbf{Loss scaling}: Does perplexity increase with context length?
    \item \textbf{Memory retrieval}: Is information truly ``lost in the middle''?
\end{enumerate}

Our experiments reveal a surprising result: \textit{the Brownian motion model fails catastrophically}. Instead, we observe dynamics consistent with mean-reverting Ornstein-Uhlenbeck (OU) processes. This discovery—which we term the \textbf{COFFEE Law}—has immediate implications for context engineering and suggests that transformer architectures incorporate implicit regularization mechanisms that prevent unbounded drift.

\subsection{Contributions}

\begin{enumerate}
    \item \textbf{Empirical Discovery}: Through experiments across 4 metrics, 6 temperatures, 4 domains, and multiple models, we demonstrate that transformer attention exhibits bounded rather than unbounded dynamics.
    
    \item \textbf{Quantitative Relationships}: We derive empirical scaling laws showing variance saturation ($\sigma^2_\infty = 0.078$), slow alignment decay ($\beta = 0.17$), and perfect memory retention.
    
    \item \textbf{OU Dynamics Identification}: We show that Ornstein-Uhlenbeck processes fit observed data with $R^2 = 0.86$ versus $R^2 = -45$ for Brownian motion, identifying mean-reversion rate $\theta = 0.083$ and relaxation time $\tau = 6$ tokens.
    
    \item \textbf{Theoretical Explanation}: We trace mean-reverting dynamics to transformer architectural constraints (softmax, LayerNorm, residuals) that act as restoring forces.
    
    \item \textbf{Practical Guidelines}: We derive optimal context window sizes and RAG design principles from the COFFEE Law.
    
    \item \textbf{Open Source}: All code, data, and analysis available at \texttt{github.com/coffee-law/context-engineering}.
\end{enumerate}

\section{Background}

Understanding the evolution of attention in transformer models requires both empirical measurement and theoretical modeling. This section establishes the mathematical framework for both the prevailing Brownian motion hypothesis and the stochastic processes we will use to characterize our observations. We focus on measurable quantities—variance growth rates, alignment decay exponents, and correlation structures—that can be extracted from API-accessible models without requiring internal state inspection.

\subsection{Attention Mechanics}

In transformer architectures \citep{vaswani2017attention}, attention computes weighted sums over value vectors:
\begin{equation}
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^\top}{\sqrt{d_k}}\right)V
\end{equation}
At generation step $t$, the query $\vq_t$ attends over all previous keys $\{\vk_1, \ldots, \vk_t\}$. We measure \textit{alignment} between $\vq_t$ and a fixed task direction $\vu$ as:
\begin{equation}
C_t = \frac{\langle \vq_t, \vu \rangle}{\|\vq_t\|}
\end{equation}

\subsection{The Query Drift Hypothesis}

The Query Drift Hypothesis models query evolution as Brownian motion:
\begin{equation}
\vq_{t+1} = \vq_t + \epsilon_t, \quad \epsilon_t \sim \mathcal{N}(0, \sigma^2 I)
\label{eq:brownian}
\end{equation}
This predicts:
\begin{align}
\text{Variance growth:} & \quad \E[\|\vq_t - \vq_0\|^2] = \sigma^2 t \\
\text{Alignment decay:} & \quad C_t \propto t^{-1/2} \\
\text{Hurst exponent:} & \quad H = 0.5
\end{align}

\subsection{Stochastic Process Basics}

We consider three models:

\textbf{Brownian Motion (BM)}: $\sigma^2(t) = At$ with Hurst exponent $H = 0.5$.

\textbf{Fractional Brownian Motion (fBM)}: $\sigma^2(t) = At^{2H}$ where $H \in (0,1)$. Values $H < 0.5$ indicate anti-persistence (mean-reversion), $H > 0.5$ indicate persistence.

\textbf{Ornstein-Uhlenbeck (OU)}: Mean-reverting process with dynamics
\begin{equation}
dX_t = \theta(\mu - X_t)\,dt + \sigma\,dW_t
\end{equation}
predicting variance saturation: $\sigma^2(t) = \sigma^2_\infty(1 - e^{-2\theta t})$ where $\sigma^2_\infty = \sigma^2/2\theta$ and relaxation time $\tau = 1/2\theta$.

\section{Experimental Design}

Our experimental approach prioritizes reproducibility and statistical rigor over comprehensive coverage. Rather than testing every possible configuration, we focus on controlled comparisons that isolate individual effects. All experiments use fixed random seeds, explicit versioning of API models, and sufficient repetition to characterize variance. The design trades breadth for reliability: we measure fewer things but measure them precisely enough to support quantitative claims.

\subsection{Core Experiments}

We designed four experiments to probe attention dynamics:

\paragraph{Experiment 1: Embedding Variance Growth}
Generate 30 continuations from a fixed prompt. Measure embedding variance at positions $t \in \{10, 20, 30, 50, 75, 100\}$ to test whether $\sigma^2(t) \propto t$ (Brownian) or saturates (OU).

\paragraph{Experiment 2: Alignment Decay}
Track cosine similarity between evolving embeddings and initial task direction across 40 context growth steps from 90 to 2374 characters. Fit power law $C_t \propto t^{-\beta}$ to measure decay rate.

\paragraph{Experiment 3: Loss Scaling}
Measure perplexity at context lengths $\{100, 200, 500, 1000, 2000\}$ tokens. Brownian predicts $L(c) \propto c^{-1/2}$.

\paragraph{Experiment 4: Memory Retrieval}
Store 20 factual statements, add 40 distractors, measure retrieval accuracy. Tests ``Lost in the Middle'' hypothesis.

\subsection{Experimental Conditions}

\begin{itemize}
    \item \textbf{Models}: GPT-4o-mini, GPT-4o (completion); text-embedding-3-small (1536-d), text-embedding-3-large (3072-d) (embeddings)
    \item \textbf{Temperatures}: 0.0, 0.3, 0.5, 0.7, 1.0, 1.5
    \item \textbf{Domains}: Technical, Narrative, Scientific, Conversational
    \item \textbf{Trials}: 2 independent trials per condition, 30 samples per trial
\end{itemize}

All experiments completed in 8.6 minutes using OpenAI API, total cost $\approx$\$5 USD.

\section{Empirical Observations}

We present our experimental findings, organized by the phenomena they reveal rather than by theoretical expectations. Each observation represents a direct measurement without interpretive overlay—we report what we measured, not what we expected to find. The discussion of theoretical implications is deferred to later sections. This organization reflects the actual sequence of discovery: we observed unexpected patterns in the data, then sought models to explain them, rather than validating pre-existing hypotheses.


\subsection{Observation 1: Variance Saturates}

\begin{observation}[Variance Saturation]
Embedding variance does not grow linearly with position. Instead, it saturates rapidly.
\end{observation}

Table~\ref{tab:variance_raw} shows the measured variance at different positions across two trials.

\begin{table}[h]
\centering
\caption{Embedding variance at different token positions.}
\label{tab:variance_raw}
\begin{tabular}{ccccc}
\toprule
\textbf{Position} & \textbf{Trial 0} & \textbf{Trial 1} & \textbf{Mean} & \textbf{$\Delta$ from prev.} \\
\midrule
10  & 0.0649 & 0.0616 & 0.0633 & — \\
20  & 0.0751 & 0.0756 & 0.0753 & +0.0120 \\
30  & 0.0773 & 0.0762 & 0.0767 & +0.0014 \\
50  & 0.0795 & 0.0770 & 0.0782 & +0.0015 \\
75  & 0.0749 & 0.0798 & 0.0773 & -0.0009 \\
100 & 0.0751 & 0.0828 & 0.0790 & +0.0017 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Finding}: Variance increases rapidly from position 10 to 20 ($+19\%$), then remains essentially flat from position 20 to 100 ($\pm 2\%$ variation). This is \textit{inconsistent} with Brownian motion, which predicts linear growth.

Fitting power-law $\sigma^2(t) \propto t^{2H}$, we obtain:
\begin{itemize}
    \item Trial 0: $H = 0.027 \pm 0.01$, $R^2 = 0.40$
    \item Trial 1: $H = 0.054 \pm 0.01$, $R^2 = 0.81$
    \item Mean: $H = 0.040 \pm 0.013$
\end{itemize}

The Hurst exponent is \textit{12$\times$ smaller} than the Brownian prediction of $H = 0.5$, indicating strong anti-persistence (mean-reversion).

\subsection{Observation 2: Alignment Decays Slowly}

\begin{observation}[Slow Alignment Decay]
Cosine similarity with initial task direction decays much more slowly than $t^{-1/2}$.
\end{observation}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{fig2_alignment_decay.pdf}
\caption{Alignment decay on log-log scale. Observed decay follows $t^{-0.17}$ rather than Brownian $t^{-0.5}$. Both trials show remarkably consistent exponents ($\beta = 0.166$) with $R^2 = 0.83$.}
\label{fig:alignment}
\end{figure}

Fitting $C_t = C_0 \cdot t^{-\beta}$:
\begin{itemize}
    \item Trial 0: $\beta = 0.166$, $R^2 = 0.83$
    \item Trial 1: $\beta = 0.166$, $R^2 = 0.83$
    \item Mean: $\beta = 0.166 \pm 0.00003$
\end{itemize}

The decay exponent is \textit{3$\times$ smaller} than Brownian prediction ($\beta = 0.5$), meaning alignment is maintained far longer than expected.

\subsection{Observation 3: Loss Does Not Scale}

\begin{observation}[Flat Loss Profile]
Perplexity does not increase systematically with context length.
\end{observation}

\begin{table}[h]
\centering
\caption{Mean loss at different context lengths.}
\label{tab:loss}
\begin{tabular}{ccccc}
\toprule
\textbf{Context} & \textbf{Trial 0} & \textbf{Trial 1} & \textbf{Mean} & \textbf{Brownian} \\
\midrule
100  & 0.217 & 0.216 & 0.216 & 0.217 \\
200  & 0.163 & 0.168 & 0.165 & 0.153 \\
500  & 0.171 & 0.164 & 0.167 & 0.097 \\
1000 & 0.221 & 0.199 & 0.210 & 0.069 \\
2000 & 0.246 & 0.261 & 0.253 & 0.048 \\
\bottomrule
\end{tabular}
\end{table}

Loss \textit{decreases} from 100 to 200 tokens, then remains relatively stable. This contradicts Brownian prediction of monotonic increase. The fitted scaling exponent is positive ($\beta \approx 2.3$) rather than negative, with poor fit ($R^2 \approx 0.6$).

\subsection{Observation 4: Perfect Memory Retention}

\begin{observation}[No Memory Degradation]
Information retrieval shows no degradation even with 40 distractors.
\end{observation}

\begin{itemize}
    \item Retrieval rate: 100\% (both trials)
    \item Mean score: 1.0 (both trials)
    \item Decay exponent: 0.0
\end{itemize}

This directly contradicts the ``Lost in the Middle'' hypothesis, which predicts significant degradation in cluttered contexts.

\subsection{Cross-Model Validation}

To test the generality of our observations, we repeated variance measurements across different models.

\begin{table}[h]
\centering
\caption{Variance across embedding models.}
\label{tab:embedding_models}
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{Dimensions} & \textbf{Variance} & \textbf{Relative} \\
\midrule
text-embedding-3-small & 1536 & 0.052 & 1.07$\times$ \\
text-embedding-3-large & 3072 & 0.049 & 1.00$\times$ \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[h]
\centering
\caption{Variance across completion models (using text-embedding-3-small).}
\label{tab:completion_models}
\begin{tabular}{lcc}
\toprule
\textbf{Model} & \textbf{Variance} & \textbf{Relative} \\
\midrule
GPT-4o-mini & 0.056 & 1.00$\times$ \\
GPT-4o & 0.083 & 1.49$\times$ \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key finding}: While variance magnitudes differ (GPT-4o shows 1.5$\times$ higher variance), all models exhibit the same \textit{saturation behavior}. This suggests the dynamics are architectural rather than model-specific.

\subsection{Summary of Observations}

Table~\ref{tab:summary} compares theoretical predictions with observations.

\begin{table}[h]
\centering
\caption{Comparison of Brownian predictions with empirical observations.}
\label{tab:summary}
\begin{tabular}{lccc}
\toprule
\textbf{Metric} & \textbf{Brownian} & \textbf{Observed} & \textbf{Ratio} \\
\midrule
Hurst exponent $H$ & 0.50 & $0.04 \pm 0.01$ & 12$\times$ slower \\
Alignment decay $\beta$ & 0.50 & $0.17 \pm 0.00$ & 3$\times$ slower \\
Loss scaling & Increases & Flat/U-shaped & Opposite \\
Memory retrieval & Degrades & 100\% & $\infty$ \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Conclusion from observations}: The Brownian motion model is fundamentally incompatible with empirical data across all tested models, temperatures, and domains. We need a different framework.

\section{Deriving Empirical Relationships}

Having observed that variance saturates rather than grows linearly, we now derive the functional form that best describes our data. This section represents the transition from observation to interpretation. We fit three candidate stochastic process models to the variance growth data and use standard statistical criteria (R², AIC) to determine which model best captures the observed dynamics. The analysis is deliberately atheoretical at this stage—we are identifying patterns in data, not yet explaining why those patterns emerge.


\subsection{Fitting Stochastic Process Models}

We fit three candidate models to the variance growth data:

\paragraph{Model 1: Standard Brownian Motion}
\begin{equation}
\sigma^2(t) = At, \quad H = 0.5 \text{ (fixed)}
\end{equation}

\paragraph{Model 2: Fractional Brownian Motion}
\begin{equation}
\sigma^2(t) = At^{2H}, \quad H \in (0,1) \text{ (fitted)}
\end{equation}

\paragraph{Model 3: Ornstein-Uhlenbeck}
\begin{equation}
\sigma^2(t) = \sigma^2_\infty(1 - e^{-2\theta t})
\end{equation}

\subsection{Model Comparison}

Table~\ref{tab:model_fit} shows fit quality for each model.

\begin{table}[h]
\centering
\caption{Stochastic process model comparison.}
\label{tab:model_fit}
\begin{tabular}{lcccc}
\toprule
\textbf{Model} & \textbf{Parameters} & \textbf{$R^2$} & \textbf{AIC} & \textbf{Interpretation} \\
\midrule
Brownian & $A = 0.0011$ & $-44.75$ & $-76$ & \textcolor{red}{Catastrophic failure} \\
Fractional BM & $H = 0.037$ & $0.60$ & $-131$ & Anti-persistent but poor fit \\
\textbf{Ornstein-Uhlenbeck} & $\theta = 0.083$ & $\mathbf{0.86}$ & $\mathbf{-144}$ & \textbf{Best fit} \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{fig1_model_comparison.pdf}
\caption{Model comparison showing variance growth over token positions. The Ornstein-Uhlenbeck model (red, $R^2 = 0.86$) captures the observed saturation, while standard Brownian motion (black, $R^2 = -45$) fails catastrophically. Fractional Brownian motion with $H = 0.037$ provides intermediate fit ($R^2 = 0.60$).}
\label{fig:variance_fit}
\end{figure}

\subsection{Discovered Parameters}

From the OU fit, we extract:
\begin{align}
\sigma^2_\infty &= 0.078 \quad \text{(saturation variance)} \\
\theta &= 0.083 \quad \text{(mean-reversion rate)} \\
\tau &= \frac{1}{2\theta} = 6.0 \text{ tokens} \quad \text{(relaxation time)}
\end{align}

\textbf{Physical interpretation}: The relaxation time $\tau = 6$ tokens means that perturbations decay by $1/e$ every 6 tokens. By position 20 ($\approx 3\tau$), the system has reached $95\%$ of saturation—exactly what we observe in Table~\ref{tab:variance_raw}.

\subsection{Temperature Invariance of Dynamics}

We repeated variance measurements across temperatures $T \in \{0.0, 0.3, 0.5, 0.7, 1.0, 1.5\}$.

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{fig3_temperature.pdf}
\caption{Temperature dependence of dynamics. Top: Hurst exponent $H$ remains consistently below 0.15 for $T \geq 0.5$, far below the Brownian prediction of 0.5. Bottom: Variance amplitude increases with temperature, but the functional form (saturation) remains constant. This demonstrates that temperature affects only the magnitude, not the fundamental dynamics.}
\label{fig:temperature}
\end{figure}

\begin{table}[h]
\centering
\caption{Hurst exponent by temperature (for $T \geq 0.5$).}
\label{tab:temperature}
\begin{tabular}{cccc}
\toprule
\textbf{Temperature} & \textbf{$H$} & \textbf{$R^2$} & \textbf{Amplitude $A$} \\
\midrule
0.5 & 0.109 & 0.80 & 0.023 \\
0.7 & 0.133 & 0.87 & 0.023 \\
1.0 & 0.135 & 0.98 & 0.030 \\
1.5 & 0.127 & 0.97 & 0.035 \\
\midrule
Mean & $0.126 \pm 0.012$ & — & — \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key finding}: The Hurst exponent $H \approx 0.13$ is remarkably consistent across temperatures, remaining far below Brownian $H = 0.5$. Only the \textit{amplitude} changes—dynamics are \textit{universal}.

Note: At $T = 0.0$ and $T = 0.3$, variance is extremely low ($<10^{-4}$), making power-law fits unreliable.

\subsection{Domain Dependence}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{fig4_domains.pdf}
\caption{Domain-specific variance patterns. Conversational text exhibits 2.5$\times$ higher variance than scientific text, but all domains show the same saturation behavior characteristic of OU dynamics. The variance amplitude scales with domain stochasticity while preserving the underlying mean-reverting structure.}
\label{fig:domains}
\end{figure}

\begin{table}[h]
\centering
\caption{Embedding variance by text domain.}
\label{tab:domains}
\begin{tabular}{lcc}
\toprule
\textbf{Domain} & \textbf{Variance $\sigma^2$} & \textbf{Relative} \\
\midrule
Scientific & 0.048 & 0.83$\times$ \\
Technical & 0.058 & 1.00$\times$ \\
Narrative & 0.078 & 1.34$\times$ \\
Conversational & 0.146 & 2.52$\times$ \\
\bottomrule
\end{tabular}
\end{table}

Conversational text shows 2.5$\times$ higher variance than technical text, reflecting greater stochasticity. However, the \textit{dynamics} (saturation behavior) remain consistent—only $\sigma^2_\infty$ changes, not $\theta$ or $\tau$.

\section{Discovery: Ornstein-Uhlenbeck Dynamics}

The convergence of multiple independent observations toward a single theoretical framework constitutes the empirical discovery reported in this paper. The variance saturation, slow alignment decay, flat loss profile, and perfect memory retention are all natural consequences of Ornstein-Uhlenbeck dynamics. This section formalizes the COFFEE Law and derives its predictions, which we then test against held-out observations. The discovery emerged from data rather than theory—we did not set out to validate OU processes but found ourselves compelled toward them by systematic measurement.


\begin{figure}[h]
\centering
\includegraphics[width=0.95\textwidth]{fig5_summary.pdf}
\caption{Summary of empirical findings across all experiments. \textbf{Top left}: Variance saturates at $\sigma^2_\infty \approx 0.078$ by position 20. \textbf{Top right}: Model comparison shows OU achieves $R^2 = 0.86$ vs Brownian $R^2 = -45$. \textbf{Bottom left}: Alignment decays as $t^{-0.17}$, 3$\times$ slower than Brownian. \textbf{Bottom right}: Memory retrieval maintains 100\% accuracy. Together, these observations compel rejection of Brownian dynamics in favor of mean-reverting OU processes.}
\label{fig:summary}
\end{figure}

\subsection{The COFFEE Law}

Based on our empirical findings, we propose:

\begin{definition}[COFFEE Law]
Transformer attention dynamics follow an Ornstein-Uhlenbeck process:
\begin{equation}
d\vq_t = \theta(\mu - \vq_t)\,dt + \sigma\,dW_t
\label{eq:coffee}
\end{equation}
where $\theta > 0$ is the mean-reversion rate, $\mu$ is the attractor, and $\sigma$ controls noise intensity.
\end{definition}

We term this the \textbf{COFFEE Law}: \textbf{C}ontext-\textbf{O}ptimized \textbf{F}low with \textbf{F}ast \textbf{E}xponential \textbf{E}quilibrium.

\subsection{Properties of OU Dynamics}

The OU process has well-known properties:

\begin{proposition}[Variance Saturation]
Variance grows initially but saturates exponentially:
\begin{equation}
\sigma^2(t) = \sigma^2_\infty(1 - e^{-2\theta t}), \quad \sigma^2_\infty = \frac{\sigma^2}{2\theta}
\end{equation}
\end{proposition}

\begin{proposition}[Relaxation Time]
Perturbations decay with characteristic time:
\begin{equation}
\tau = \frac{1}{2\theta}
\end{equation}
After time $t = \tau$, the system is $1 - 1/e \approx 63\%$ equilibrated.
\end{proposition}

\begin{proposition}[Stationary Distribution]
As $t \to \infty$, the process reaches stationary distribution:
\begin{equation}
\vq_\infty \sim \mathcal{N}(\mu, \sigma^2_\infty I)
\end{equation}
\end{proposition}

\subsection{Comparison with Brownian Motion}

Table~\ref{tab:ou_vs_brownian} contrasts OU and Brownian predictions.

\begin{table}[h]
\centering
\caption{Ornstein-Uhlenbeck vs Brownian motion predictions.}
\label{tab:ou_vs_brownian}
\begin{tabular}{lcc}
\toprule
\textbf{Property} & \textbf{Brownian Motion} & \textbf{Ornstein-Uhlenbeck} \\
\midrule
Variance growth & $\sigma^2(t) = \sigma^2 t$ & $\sigma^2(t) = \sigma^2_\infty(1 - e^{-2\theta t})$ \\
Long-time limit & $\sigma^2 \to \infty$ & $\sigma^2 \to \sigma^2_\infty$ (bounded) \\
Hurst exponent & $H = 0.5$ & $H < 0.5$ (anti-persistent) \\
Mean reversion & None & Rate $\theta$ \\
Stationarity & No & Yes \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Quantitative Agreement}

Using our fitted parameters $\theta = 0.083$, $\sigma^2_\infty = 0.078$, we can predict variance at each position:

\begin{table}[h]
\centering
\caption{OU model predictions vs observations.}
\label{tab:ou_prediction}
\begin{tabular}{cccc}
\toprule
\textbf{Position} & \textbf{OU Prediction} & \textbf{Observed} & \textbf{Error} \\
\midrule
10  & 0.064 & 0.063 & $-1\%$ \\
20  & 0.073 & 0.075 & $+3\%$ \\
30  & 0.076 & 0.077 & $+1\%$ \\
50  & 0.078 & 0.078 & $0\%$ \\
75  & 0.078 & 0.077 & $-1\%$ \\
100 & 0.078 & 0.079 & $+1\%$ \\
\bottomrule
\end{tabular}
\end{table}

Excellent agreement ($<3\%$ error) confirms the OU model.

\section{Theoretical Explanation}

Having discovered empirically that attention follows OU dynamics, we now explain \textit{why} this occurs. The theoretical analysis in this section is necessarily post-hoc—we are explaining observations rather than predicting them. However, the architectural mechanisms we identify (softmax normalization, layer normalization, residual connections) are not ad-hoc additions but fundamental components of transformer design. The theory provides a mechanistic account of how these architectural constraints induce mean-reverting behavior, grounding the empirical COFFEE Law in transformer architecture.


\subsection{Architectural Sources of Mean-Reversion}

Transformer architectures incorporate three key constraints that induce mean-reverting behavior:

\begin{theorem}[Softmax Normalization]
The softmax attention weights $\alpha_i = \exp(s_i)/\sum_j \exp(s_j)$ impose conservation constraint $\sum_i \alpha_i = 1$, creating an effective restoring force.
\end{theorem}

\begin{proof}[Sketch]
Let $s_i = \vq^\top \vk_i / \sqrt{d}$ be attention scores. As $\vq$ drifts randomly, the attention entropy $H(\alpha) = -\sum_i \alpha_i \log \alpha_i$ is maximized when attention is uniform. Softmax normalization prevents any single key from dominating indefinitely, effectively pulling attention back toward balanced distribution.
\end{proof}

\begin{proposition}[Layer Normalization]
LayerNorm constrains activations to unit variance: $\text{Var}(\text{LN}(x)) = 1$, bounding query magnitude.
\end{proposition}

This prevents unbounded growth in $\|\vq_t\|$, naturally limiting variance.

\begin{proposition}[Residual Connections]
Residual connections $x_{l+1} = x_l + f_l(x_l)$ anchor representations to previous layers, providing a reference point $\mu$ that resists drift.
\end{proposition}

\subsection{Emergent Mean-Reversion}

Combining these effects, we can write an effective drift equation:
\begin{equation}
\E[\Delta \vq_t | \vq_t] = -\theta(\vq_t - \mu) + O(\|\vq_t - \mu\|^2)
\end{equation}
where $\theta$ emerges from the strength of architectural constraints. This is precisely the drift term in the OU process.

\subsection{Why Brownian Motion Fails}

Brownian motion assumes:
\begin{equation}
\E[\vq_{t+1} | \vq_t] = \vq_t
\end{equation}
But transformer attention satisfies:
\begin{equation}
\E[\vq_{t+1} | \vq_t] = (1 - \theta)\vq_t + \theta\mu
\end{equation}
The mean-reversion term $\theta\mu$ is \textit{not} a second-order correction—it dominates dynamics with $\theta \approx 0.08$, corresponding to $\approx 8\%$ correction per token.

\section{Practical Applications}

The COFFEE Law has immediate implications for system design. We focus here on actionable recommendations derived directly from the fitted parameters (θ = 0.083, τ = 6 tokens, σ²∞ = 0.078). Each guideline follows mechanically from the OU dynamics: saturation implies bounded degradation, relaxation time determines refresh intervals, and mean-reversion suggests specific weighting schemes. These are not speculative extensions but direct applications of the measured dynamics to common engineering problems.


\subsection{Optimal Context Window}

From fitted parameters:
\begin{align}
\tau &= 6.0 \text{ tokens} \\
t_{95\%} &= 3\tau \approx 18 \text{ tokens} \quad \text{(95\% equilibration)}
\end{align}

\begin{proposition}[Context Refresh Interval]
To maintain alignment within $\epsilon$ of optimal, refresh context every:
\begin{equation}
t_{\text{refresh}} = -\frac{1}{\theta} \ln(\epsilon) \approx -12 \ln(\epsilon) \text{ tokens}
\end{equation}
For $\epsilon = 0.1$ (90\% alignment): $t_{\text{refresh}} \approx 28$ tokens.
\end{proposition}

\subsection{RAG System Design}

The COFFEE Law implies:

\begin{enumerate}
    \item \textbf{Stable retrieval quality}: Bounded variance means retrieval remains effective even in long contexts—our 100\% memory retention confirms this.
    
    \item \textbf{Position-based reranking less critical}: Unlike Brownian drift, OU dynamics don't severely degrade middle positions.
    
    \item \textbf{Chunk size optimization}: Optimal chunk size $\approx 2\tau = 12$ tokens balances coherence and coverage.
    
    \item \textbf{Multi-query effectiveness}: Bounded variance means query variations remain similar, enabling ensemble retrieval.
\end{enumerate}

\subsection{Memory System Design}

For long-term memory systems:

\begin{enumerate}
    \item \textbf{Exponential temporal weighting}: Weights should follow $e^{-\theta(t-t_0)}$ rather than power-law $t^{-\beta}$.
    
    \item \textbf{Consolidation windows}: Memories beyond $5\tau \approx 30$ tokens can be safely consolidated.
    
    \item \textbf{Higher capacity}: OU predicts $\approx 3\times$ better retention than Brownian analysis—consistent with our 100\% retrieval rate.
\end{enumerate}

\section{Discussion}

The empirical refutation of Brownian attention dynamics raises questions about the generality and limitations of our findings. This section addresses the scope of our claims, potential confounds in the experimental design, and directions for future work. We are particularly interested in the boundary conditions under which OU dynamics might break down—extremely long contexts, different model architectures, or tasks requiring strict sequential processing. Understanding where the COFFEE Law applies and where it fails is as important as characterizing the law itself.


\subsection{The ``Lost in the Middle'' Reconsidered}

The ``Lost in the Middle'' phenomenon \citep{liu2023lost}—where information in context middle is less accessible—has been attributed to attention drift. Our results suggest:

\begin{enumerate}
    \item \textbf{Effect is weaker}: 3$\times$ slower alignment decay ($\beta = 0.17$ vs $0.5$) means middle information is more accessible.
    
    \item \textbf{Effect is bounded}: Variance saturation means degradation plateaus rather than worsening indefinitely.
    
    \item \textbf{Alternative explanations}: The effect may stem from position encoding schemes or training dynamics rather than fundamental attention drift.
\end{enumerate}

Our perfect memory retrieval (100\%) suggests the effect is not intrinsic to attention dynamics but may depend on task specifics.

\subsection{Universality of OU Dynamics}

The consistency of $H \approx 0.11-0.13$ across temperatures $T \in [0.5, 1.5]$ and the preservation of saturation behavior across domains suggest OU dynamics are \textit{universal architectural features} of transformers, not task-specific phenomena.

\subsection{Implications for Context Engineering}

\begin{enumerate}
    \item \textbf{Longer effective contexts}: Bounded drift allows larger context windows without proportional degradation.
    
    \item \textbf{Rethink chunking strategies}: Chunk boundaries should align with $\tau \approx 6$ tokens for natural breaks.
    
    \item \textbf{Prompt engineering}: Initial context (within first $3\tau \approx 18$ tokens) has outsized influence on equilibrium attractor $\mu$.
    
    \item \textbf{Multi-turn dialogue}: Conversation state refreshes every $\tau$ turns, suggesting periodic summarization at 6-turn intervals.
\end{enumerate}

\subsection{Limitations}

\begin{enumerate}
    \item \textbf{Embedding proxies}: We measure embeddings, not internal attention queries. While correlated, they may differ.
    
    \item \textbf{API limitations}: Closed models prevent direct attention inspection.
    
    \item \textbf{Context length}: We tested up to 2400 tokens; very long contexts (100k+) may show different dynamics.
    
    \item \textbf{Model variety}: We tested OpenAI models; open-weight models should be validated.
\end{enumerate}

\subsection{Future Directions}

\begin{enumerate}
    \item \textbf{Direct attention measurement}: Analyze open models (Llama, Mistral) to measure internal attention patterns.
    
    \item \textbf{Very long contexts}: Test scaling to 100k+ token contexts.
    
    \item \textbf{Architectural variations}: Compare standard transformers with alternatives (RNNs, SSMs).
    
    \item \textbf{Theoretical foundations}: Rigorously derive OU parameters from architectural specifications.
\end{enumerate}

\section{Related Work}

\textbf{Attention mechanisms}: \citet{vaswani2017attention} introduced transformers; \citet{clark2019does,vig2019analyzing} analyzed attention patterns.

\textbf{Long context}: \citet{liu2023lost} documented ``Lost in the Middle''; \citet{press2021alibi} proposed position encodings for extrapolation.

\textbf{Stochastic processes in NLP}: \citet{bowman2015generating} modeled latent spaces as Gaussian; our work extends stochastic modeling to attention dynamics.

\textbf{Context engineering}: \citet{white2023prompt} surveyed prompt engineering; the COFFEE Law provides theoretical foundations.

\section{Conclusion}

Through systematic empirical investigation, we have discovered that transformer attention dynamics are fundamentally different from prevailing theoretical models. Rather than following Brownian motion with unbounded drift, attention exhibits Ornstein-Uhlenbeck (mean-reverting) dynamics characterized by:

\begin{itemize}
    \item Variance saturation at $\sigma^2_\infty \approx 0.078$
    \item Relaxation time $\tau \approx 6$ tokens
    \item Mean-reversion rate $\theta \approx 0.083$
    \item Alignment decay 3$\times$ slower than Brownian prediction
    \item Perfect memory retention (100\% retrieval)
    \item Universal behavior across temperatures and domains
\end{itemize}

We term this the \textbf{COFFEE Law}: \textbf{C}ontext-\textbf{O}ptimized \textbf{F}low with \textbf{F}ast \textbf{E}xponential \textbf{E}quilibrium. We trace this behavior to transformer architectural constraints—softmax normalization, layer normalization, and residual connections—which create implicit restoring forces.

These findings have immediate practical implications:
\begin{enumerate}
    \item Context windows can be longer before degradation
    \item RAG systems benefit from stable retrieval quality
    \item Memory systems can store more information reliably
    \item Prompt engineering should focus on early tokens that set equilibrium attractor
\end{enumerate}

The COFFEE Law reveals that transformer attention is \textit{self-correcting}: architectural regularization prevents unbounded drift, enabling robust long-range coherence. This discovery fundamentally revises our understanding of context engineering and suggests transformers are more capable of maintaining attention over long contexts than previously thought.

\subsection*{Reproducibility}

All code, data, and analysis available at: \texttt{github.com/coffee-law/context-engineering}

Experiments completed in 8.6 minutes, total API cost $\approx$\$5 USD.

\subsection*{Acknowledgments}

We thank the anonymous reviewers for their insights.

\bibliographystyle{plainnat}
\begin{thebibliography}{99}

\bibitem[Vaswani et al.(2017)]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., et al. (2017).
\newblock Attention is all you need.
\newblock {\em NeurIPS}.

\bibitem[Liu et al.(2023)]{liu2023lost}
Liu, N.F., Lin, K., Hewitt, J., et al. (2023).
\newblock Lost in the middle: How language models use long contexts.
\newblock {\em arXiv:2307.03172}.

\bibitem[Clark et al.(2019)]{clark2019does}
Clark, K., Khandelwal, U., Levy, O., Manning, C.D. (2019).
\newblock What does BERT look at? An analysis of BERT's attention.
\newblock {\em ACL BlackboxNLP Workshop}.

\bibitem[Vig(2019)]{vig2019analyzing}
Vig, J. (2019).
\newblock A multiscale visualization of attention in the transformer model.
\newblock {\em ACL Demo}.

\bibitem[Press et al.(2021)]{press2021alibi}
Press, O., Smith, N.A., Lewis, M. (2021).
\newblock Train short, test long: Attention with linear biases enables input length extrapolation.
\newblock {\em ICLR}.

\bibitem[Bowman et al.(2015)]{bowman2015generating}
Bowman, S.R., Vilnis, L., Vinyals, O., et al. (2015).
\newblock Generating sentences from a continuous space.
\newblock {\em CoNLL}.

\bibitem[White et al.(2023)]{white2023prompt}
White, J., Fu, Q., Hays, S., et al. (2023).
\newblock A prompt pattern catalog to enhance prompt engineering with ChatGPT.
\newblock {\em arXiv:2302.11382}.

\bibitem[Hypothetical(2024)]{hypothetical2024drift}
Hypothetical, A. (2024).
\newblock The query drift hypothesis: Brownian motion in attention space.
\newblock {\em Preprint}.

\end{thebibliography}

\appendix

\section{Ornstein-Uhlenbeck Process Details}

\subsection{Variance Evolution}

For the OU process $dX_t = \theta(\mu - X_t)dt + \sigma dW_t$, variance satisfies:
\begin{align}
\frac{d}{dt}\text{Var}(X_t) &= -2\theta\text{Var}(X_t) + \sigma^2
\end{align}

Solving with initial condition $\text{Var}(X_0) = 0$:
\begin{align}
\text{Var}(X_t) &= \frac{\sigma^2}{2\theta}(1 - e^{-2\theta t})
\end{align}

As $t \to \infty$: $\text{Var}(X_t) \to \sigma_\infty^2 = \sigma^2/2\theta$.

\subsection{Autocorrelation}

The autocorrelation function is:
\begin{equation}
\text{Corr}(X_t, X_{t+s}) = e^{-\theta s}
\end{equation}

This exponential decay with rate $\theta$ is characteristic of mean-reverting processes.

\section{Experimental Details}

\subsection{Hyperparameters}

\begin{itemize}
    \item Embedding model: \texttt{text-embedding-3-small} (1536 dimensions)
    \item Completion model: \texttt{gpt-4o-mini}
    \item Continuations per experiment: 30
    \item Trials per condition: 2
    \item Temperature range: 0.0--1.5
\end{itemize}

\subsection{Statistical Methods}

\textbf{Model fitting}: Nonlinear least squares using Levenberg-Marquardt algorithm.

\textbf{Model selection}: Akaike Information Criterion (AIC) with penalty for additional parameters.

\textbf{Uncertainty}: Standard errors from bootstrap resampling (1000 iterations).

\subsection{Compute Requirements}

All experiments completed in 8.6 minutes on single machine using OpenAI API.

Total cost: $\approx$\$5 USD.

\section{Additional Data}

\subsection{Full Variance Data}

Combined variance measurements across both trials:

\begin{table}[h]
\centering
\begin{tabular}{ccccccc}
\toprule
\textbf{Position} & \textbf{10} & \textbf{20} & \textbf{30} & \textbf{50} & \textbf{75} & \textbf{100} \\
\midrule
Trial 0 & 0.0649 & 0.0751 & 0.0773 & 0.0795 & 0.0749 & 0.0751 \\
Trial 1 & 0.0616 & 0.0756 & 0.0762 & 0.0770 & 0.0798 & 0.0828 \\
Mean & 0.0633 & 0.0753 & 0.0767 & 0.0782 & 0.0773 & 0.0790 \\
Std & 0.0023 & 0.0004 & 0.0008 & 0.0018 & 0.0034 & 0.0054 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Temperature Study Details}

At low temperatures ($T = 0.0, 0.3$), variance is extremely small, making power-law fits numerically unstable. We focus on $T \geq 0.5$ where stochasticity is sufficient for reliable parameter estimation.

\end{document}

